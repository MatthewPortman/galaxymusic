{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c0d21d8-ae76-47f5-876d-e61d0f7881e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install xgboost\n",
    "# !pip install hyperopt\n",
    "# !pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33eb3154-59cc-49b0-82ed-4fbde6fc00b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc6e39f9-ebaa-4c7a-8ab6-0e38336b8507",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For debugging purposes\n",
    "from IPython import get_ipython\n",
    "def in_notebook():\n",
    "    ip = get_ipython()\n",
    "    \n",
    "    if ip:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7376b1eb-f58b-4136-8fa5-0fd81c6e3fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from os.path import join as pj\n",
    "from os.path import exists\n",
    "\n",
    "_HOME_DIR = os.path.expanduser(\"~\")\n",
    "if in_notebook():\n",
    "    _SPARCFIRE_DIR = pj(_HOME_DIR, \"sparcfire_matt\") \n",
    "    _MODULE_DIR    = pj(_SPARCFIRE_DIR, \"GalfitModule\")\n",
    "else:\n",
    "    try:\n",
    "        _SPARCFIRE_DIR = os.environ[\"SPARCFIRE_HOME\"]\n",
    "        _MODULE_DIR = pj(_SPARCFIRE_DIR, \"GalfitModule\")\n",
    "    except KeyError:\n",
    "        if __name__ == \"__main__\":\n",
    "            print(\"SPARCFIRE_HOME is not set. Please run 'setup.bash' inside SpArcFiRe directory if not done so already.\")\n",
    "            print(\"Checking the current directory for GalfitModule, otherwise quitting.\")\n",
    "            \n",
    "        _MODULE_DIR = pj(os.getcwd(), \"GalfitModule\")\n",
    "        \n",
    "        if not exists(_MODULE_DIR):\n",
    "            raise Exception(\"Could not find GalfitModule!\")\n",
    "    \n",
    "sys.path.append(_MODULE_DIR)\n",
    "from sparc_to_galfit_feedme_gen import * #get_galaxy_names_list\n",
    "from Classes.Components import *\n",
    "from Classes.Containers import FeedmeContainer\n",
    "from Functions.helper_functions import *\n",
    "from XGBoost.xgboost_functions import galfit_param_grab, flatten_to_pandas, make_hist_plots, export_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a91f44-4463-4dbb-acf5-80f2dfe3ff29",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Force >python 3.10 for various compatabilities\n",
    "    out_str = \"\\t Python3.10 or greater required! Exitting without generating feedmes...\"\n",
    "    assert sys.version_info >= (3, 10), out_str\n",
    "    \n",
    "    cwd = absp(os.getcwd()) # Doesn't work *in* notebook\n",
    "    old_cwd = absp(cwd) # Strings are immutable\n",
    "    \n",
    "    username = os.environ[\"USER\"]\n",
    "    \n",
    "    USAGE = f\"\"\"USAGE:\n",
    "\n",
    "    python3 ./{sys.argv[0]} [OPTION] [[RUN-DIRECTORY] IN-DIRECTORY TMP-DIRECTORY OUT-DIRECTORY]\n",
    "    \n",
    "    OPTIONS => [-v | --verbose]\n",
    "\n",
    "    This script is used to train XGBoost to feed better input to GALFIT via SpArcFiRe. \n",
    "    By default, it runs from the RUN (or current) directory and uses the\n",
    "    '-in' '-tmp' and '-out' directories as specified or otherwise defaults to \n",
    "    'sparcfire-in', 'sparcfire-tmp', 'sparcfire-out'. \n",
    "\n",
    "    Please do not specify symlinks for the above, they discomfort the programmer.\n",
    "    \"\"\"\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description = USAGE)\n",
    "    \n",
    "    parser.add_argument('-v', '--verbose',\n",
    "                        dest     = 'verbose', \n",
    "                        action   = 'store_const',\n",
    "                        const    = True,\n",
    "                        default  = False,\n",
    "                        help     = 'Verbose output for all bash commands in control script.'\n",
    "                       )\n",
    "    \n",
    "    parser.add_argument(dest     = 'paths',\n",
    "                        nargs    = \"*\",\n",
    "                        type     = str,\n",
    "                        help     = \"RUN-DIRECTORY [IN-DIRECTORY TMP-DIRECTORY OUT-DIRECTORY] from SpArcFiRe. \\\n",
    "                                    SpArcFiRe directories should follow -in, -tmp, -out.\"\n",
    "    \n",
    "    if not in_notebook():\n",
    "        args              = parser.parse_args() # Using vars(args) will call produce the args as a dict\n",
    "        \n",
    "        verbose           = args.verbose\n",
    "        capture_output    = not args.verbose\n",
    "                        \n",
    "        if len(args.paths) == 1:\n",
    "            cwd = args.paths[0]\n",
    "            in_dir = pj(cwd, \"sparcfire-in\")\n",
    "            tmp_dir = pj(cwd, \"sparcfire-tmp\")\n",
    "            out_dir = pj(cwd, \"sparcfire-out\")\n",
    "            \n",
    "        elif len(args.paths) == 3:\n",
    "            in_dir, tmp_dir, out_dir = args.paths[0], args.paths[1], args.paths[2]\n",
    "            \n",
    "        elif len(args.paths) == 4:\n",
    "            cwd, in_dir, tmp_dir, out_dir = args.paths[0], args.paths[1], args.paths[2], args.paths[3]\n",
    "            \n",
    "        else:\n",
    "            in_dir = pj(cwd, \"sparcfire-in\")\n",
    "            tmp_dir = pj(cwd, \"sparcfire-tmp\")\n",
    "            out_dir = pj(cwd, \"sparcfire-out\")\n",
    "            print(f\"Paths incorrectly specified, defaulting to {cwd} (-in, -tmp, -out)...\")\n",
    "            print(f\"{in_dir}\\n{tmp_dir}\\n{out_dir}\")\n",
    "            print()\n",
    "            \n",
    "        check_dir_names = [1 for i in (in_dir, tmp_dir, out_dir) if \"-\" not in i ]\n",
    "        if check_dir_names:\n",
    "            raise Exception(\"Directory paths must end in '-in' '-tmp' and '-out'\")\n",
    "            \n",
    "    else:\n",
    "        verbose = False\n",
    "        capture_output = True\n",
    "        \n",
    "        cwd = cwd.replace(\"ics-home\", username)\n",
    "        sparc_out_dir = pj(_HOME_DIR, \"run2_1000_galfit\", \"sparcfire-out\") #pj(cwd, \"sparcfire-out\")\n",
    "        \n",
    "        sys.path.append(pj(_HOME_DIR, \".local\", \"bin\"))\n",
    "        \n",
    "    # Making these absolute paths\n",
    "    cwd     = absp(cwd)\n",
    "    in_dir  = absp(in_dir)\n",
    "    tmp_dir = absp(tmp_dir)\n",
    "    out_dir = absp(out_dir)\n",
    "    \n",
    "    # Changing to specified working dir\n",
    "    os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97c7165d-7a59-482b-b9d4-1b8a99ff7cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model_xgb = xgb.XGBRegressor()\n",
    "    model_xgb.load_model(pj(cwd, \"xgboost_model.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c454ab-0417-41f9-8fd9-197d897c331f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    output_df = pd.DataFrame()\n",
    "\n",
    "    _, galaxy_names, _ = get_galaxy_names_list(in_dir)\n",
    "    \n",
    "    count = 0\n",
    "    for gname in galaxy_names:\n",
    "#         gal_dict, param_names = galfit_param_grab(pj(filepath, gname + \".in\"))\n",
    "#         if not param_names: continue\n",
    "\n",
    "        gname_df = build_df(gname = gname,\n",
    "                            label = 0,\n",
    "                            count = count,\n",
    "                            label_dirs = [in_dir],\n",
    "                            file_suffix = \".in\"\n",
    "                            ) #flatten_to_pandas(gal_dict, param_names, gname)\n",
    "        output_df = pd.concat([output_df, gname_df])\n",
    "        count += 1\n",
    "        \n",
    "    galfit_in_df = output_df\n",
    "    #galfit_in_df = galfit_in_df.drop(columns = \"Crop Rad\")\n",
    "    ignore_galfit_in, ignore_galfit_out, in_filter = export_filter()\n",
    "\n",
    "    #galfit_in_df = output_df\n",
    "    #galfit_out_df = flatten_to_pandas(galfit_param_grab(), param_names, gname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2833b3c7-e828-4ea1-b689-3aee09a735df",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # For the input galaxies, we have a lot of held values, these are uneccessary\n",
    "    # https://stackoverflow.com/a/39658662\n",
    "    nunique = galfit_in_df.nunique()\n",
    "    # Removing bar radius, adding in inner radius, and making sure it's not duplicated in future versions\n",
    "    # TODO: take this out when you've confirmed all galfit outputs are brought up to speed\n",
    "    ignore_galfit_in = list(set([i for i in ignore_galfit_in if i in galfit_in_df.columns] + [\"Spiral inner radius (pixels) disk\"]))\n",
    "\n",
    "    cols_to_drop = list(nunique[nunique == 1].index) + ignore_galfit_in\n",
    "    reduced_galfit_in_df = galfit_in_df.drop(columns = cols_to_drop)\n",
    "    # Another name change issue\n",
    "    reduced_galfit_in_df = reduced_galfit_in_df.rename(columns = {\"Spiral outer radius (pixels) disk\" : \"Spiral outer (i.e. asymptotic) radius (pixels) disk\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36ff493-1ec7-41d2-8e4b-cf24b198d884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: left off here, check that drop crop rad thing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2f8f104-64bc-4b35-b6c3-e721cf995f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_dir = pj(home_dir, \"run5_galfit_xgboosted\")\n",
    "# in_dir, tmp_dir, out_dir = command_line(top_dir)\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "093816db-7d3b-425f-8469-ae787cc2ca23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_df = pd.DataFrame()\n",
    "\n",
    "# for filepath, gname in zip(folders_out, galaxy_names):\n",
    "#     gal_dict, param_names = galfit_param_grab(pj(filepath, gname + \".out\"))\n",
    "#     if not param_names: continue\n",
    "    \n",
    "#     gname_df = flatten_to_pandas(gal_dict, param_names, gname)\n",
    "#     output_df = pd.concat([output_df, gname_df])\n",
    "\n",
    "# galfit_out_df = output_df\n",
    "# #galfit_out_df = flatten_to_pandas(galfit_param_grab(), param_names, gname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "641bd1c4-b046-4123-bd95-e6bef07b29cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# galfit_in_df = output_df\n",
    "# galfit_in_df = galfit_in_df.drop(columns = \"Crop Rad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ee7ae689-82c6-45cd-918a-a6e43b173e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do this to grab just the columns we want\n",
    "leftover = list(set(galfit_in_df.columns).difference(set(ignore_galfit_in + ignore_galfit_out)))\n",
    "# Do this to retain column order\n",
    "leftover = [col for col in galfit_in_df.columns if col in leftover]\n",
    "# Manual removal for now (since galfit changed names on me)\n",
    "try:\n",
    "    leftover.remove('Spiral outer (i.e. asymptotic) radius (pixels) disk')\n",
    "except ValueError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "92939721-2c48-4c50-aa0f-e970f21b1a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_out = model_xgb.predict(reduced_galfit_in_df)\n",
    "pred_out_df = pd.DataFrame(pred_out, columns = leftover, index = reduced_galfit_in_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "729e3151-0d83-4087-933c-272456f4116a",
   "metadata": {},
   "outputs": [],
   "source": [
    "galfit_in_df.update(pred_out_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e9d4a576-602f-4fda-9f85-73fe54b25028",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_248/2350705086.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  too_small.loc[:,\"Asymptotic spiral powerlaw disk\"] = 1\n",
      "/tmp/ipykernel_248/2350705086.py:2: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  too_small.loc[:,\"Asymptotic spiral powerlaw disk\"] = 1\n",
      "/tmp/ipykernel_248/2350705086.py:3: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  galfit_in_df.update(too_small)\n"
     ]
    }
   ],
   "source": [
    "too_small = galfit_in_df.query(\"`Asymptotic spiral powerlaw disk` < -5\")\n",
    "too_small.loc[:,\"Asymptotic spiral powerlaw disk\"] = 1\n",
    "galfit_in_df.update(too_small)\n",
    "# use this as a prefilter for training and then we won't have to do this here ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f82d4792-bd51-4efa-a077-4e5c4c74b2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Integrated magnitude bulge',\n",
       " 'Sersic index n (de Vaucouleurs n=4) bulge',\n",
       " 'Axis ratio (b/a) bulge',\n",
       " 'Position angle (PA) (deg: Up=0, Left=90) bulge',\n",
       " 'Integrated magnitude disk',\n",
       " 'R_e (effective radius)   (pix) disk',\n",
       " 'Sersic index n (de Vaucouleurs n=4) disk',\n",
       " 'Axis ratio (b/a) disk',\n",
       " 'Position angle (PA) (deg: Up=0, Left=90) disk',\n",
       " 'Cumul. rotation out to outer radius (degrees) disk',\n",
       " 'Asymptotic spiral powerlaw disk',\n",
       " 'Sky position angle disk']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leftover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7d5a173d-9ac6-4ce5-a371-aeb07d0e2c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in galfit_in_df.columns:\n",
    "    if col in leftover and (\"degree\" in col.lower() or \"angle\" in col.lower()):\n",
    "        galfit_in_df[col] *= 180/np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3f9fc579-7615-48e9-9a6b-936f1c68e3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "galfit_in_df[\"Inclination to L.o.S. (degrees) disk\"] *= 180/np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "24e07a59-8f53-48e1-b79b-44e11d61381a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The interim step until I feel confident enough in the model to step in *before* outputting these all to file\n",
    "def update_feedmes(new_in_df, top_dir = \"\"):\n",
    "    \n",
    "    in_dir, tmp_dir, out_dir = command_line(top_dir)\n",
    "    filenames_fits_in, galaxy_names, folders_out = get_galaxy_names_list(in_dir)\n",
    "    \n",
    "    psf_info = csv_sdss_info(galaxy_names)\n",
    "    \n",
    "    count = 0\n",
    "    paths_to_feedme = []\n",
    "    \n",
    "    for galaxy in folders_out:\n",
    "    \n",
    "        gname = galaxy_names[count]\n",
    "        print(gname)\n",
    "        \n",
    "        galaxy_info = new_in_df.loc[gname, :]\n",
    "        \n",
    "        if(os.path.basename(galaxy) != gname):\n",
    "            print(\"uh oh naming went wrong\")\n",
    "            sys.exit()\n",
    "            \n",
    "        bulge_rad, bulge_axis_ratio, pos_angle_bulge, \\\n",
    "            crop_rad, center_pos_x, center_pos_y, \\\n",
    "            disk_maj_axs_len, pos_angle_disk, pos_angle_power, \\\n",
    "            axis_ratio, max_arc, spin_dir, \\\n",
    "            est_arcs, inclination, bar_candidate, \\\n",
    "            alpha = galaxy_information(gname, galaxy)\n",
    "        \n",
    "        center_pos_x = float(center_pos_x)\n",
    "        center_pos_y = float(center_pos_y)\n",
    "        crop_rad = float(crop_rad)\n",
    "        \n",
    "        x1crop = round(center_pos_x - crop_rad)\n",
    "        x2crop = round(center_pos_x + crop_rad)        \n",
    "        y1crop = round(center_pos_y - crop_rad)\n",
    "        y2crop = round(center_pos_y + crop_rad)\n",
    "               \n",
    "        # Initializing Feedme\n",
    "        feedme_list = []\n",
    "        \n",
    "        # Initialize template dict\n",
    "        gt = quick_build_template() # galfit template\n",
    "        #gt = rebuild_template_dict(\"./m51.feedme\")\n",
    "    \n",
    "        #To reconstruct the z PSF (i.e., the 5th HDU) at the position (row, col) = (500, 600) from run 1336, column 2, field 51 you’d say:\n",
    "        #read_PSF psField-001336-2-0051.fit 5 500.0 600.0 foo.fit\n",
    "        run, rerun, camcol, field, psf_row, psf_col, petromag = psf_info[gname]\n",
    "        \n",
    "        # new_in_df shouldddd retain order of columns, making my life (the programmer's) easier\n",
    "        # hardcoding those should provide a good litmus test too\n",
    "        all_col = new_in_df.columns# .drop(\"Crop Rad\").values\n",
    "\n",
    "        feedme_list.append(f\"#{run}{camcol}{field}; HDU: z{psf_row}{psf_col}\")\n",
    "        feedme_list.append(\"\")\n",
    "        # Image and Galfit Control Param\n",
    "        feedme_list.append(f\"A) {filenames_fits_in[count]}\")\n",
    "        feedme_list.append(f\"B) {tmp_dir}/galfits/{gname}_out.fits\")\n",
    "        feedme_list.append(f\"C) none\")\n",
    "        # Commenting out psf for now because it's causing galfit to crash\n",
    "        feedme_list.append(f\"D) none\") #{tmp_dir}/psf_files/{gname}_psf.fits\")\n",
    "        feedme_list.append(f\"E) 1\")\n",
    "        feedme_list.append(f\"F) {tmp_dir}/galfit_masks/{gname}_star-rm.fits\")\n",
    "        feedme_list.append(f\"G) none\")  #./constraints.txt\"\n",
    "        feedme_list.append(f\"H) {x1crop:d} {x2crop:d} {y1crop:d} {y2crop:d}\")\n",
    "        feedme_list.append(f\"I) 50 50\") # psf FWHM ~= 1, Chien recommends 40-80 times this value\n",
    "        feedme_list.append(f\"J) 24.8\") # SDSS\n",
    "        feedme_list.append(f\"K) 0.396  0.396\") # SDSS\n",
    "        feedme_list.append(f\"O) regular\")\n",
    "        feedme_list.append(f\"P) 0\")\n",
    "        feedme_list.append(\"\")\n",
    "        \n",
    "        # Sersic 1\n",
    "        # Fixing as much as I can here... it's not exactly a priority.\n",
    "        feedme_list.append(f\"# Component number: 1\")\n",
    "        feedme_list.append(f\"0) sersic\")\n",
    "        feedme_list.append(f\"1) {center_pos_x:.1f} {center_pos_y:.1f} 0 0\")\n",
    "        feedme_list.append(f\"3) {galaxy_info[all_col[0]]:.2f} 1\") # Initial guess goes here\n",
    "        feedme_list.append(f\"4) {galaxy_info[all_col[1]]:.2f} 1\") \n",
    "        feedme_list.append(f\"5) {galaxy_info[all_col[2]]:.2f} 1\") # According to other paper GALFIT usually doesn't have a problem with the index\n",
    "        feedme_list.append(\"6) 0  0\")    \n",
    "        feedme_list.append(\"7) 0  0\")    \n",
    "        feedme_list.append(\"8) 0  0\")    \n",
    "        # According to other papers, bulge (esp. in spiral galaxies) averages to about 2 so this is a good starting place\n",
    "        # see https://ned.ipac.caltech.edu/level5/Sept11/Buta/Buta9.html\n",
    "        feedme_list.append(f\"9) {galaxy_info[all_col[3]]:.2f} 1\")  \n",
    "        feedme_list.append(f\"10) {galaxy_info[all_col[4]]:.2f} 1\") \n",
    "        feedme_list.append(\"\")\n",
    "    \n",
    "        # Sersic 2\n",
    "        feedme_list.append(\"# Component number: 2\")\n",
    "        feedme_list.append(f\"0) sersic\")\n",
    "        feedme_list.append(f\"1) {center_pos_x:.1f} {center_pos_y:.1f} 0 0\")\n",
    "        feedme_list.append(f\"3) {galaxy_info[all_col[5]]:.2f} 1\") \n",
    "        feedme_list.append(f\"4) {galaxy_info[all_col[6]]:.2f} 1\") # Use this for effective radius? Also 0 this one out? Will have to see how well it works in practice\n",
    "        feedme_list.append(f\"5) {galaxy_info[all_col[7]]:.2f} 1\") # Classical disk follows Sersic n = 1 so good place to start (per Readme Exponential profile)\n",
    "                                      # According to comparison tests, this usually ends up much higher probably due to the spiral.\n",
    "        feedme_list.append(\"6) 0  0\")    \n",
    "        feedme_list.append(\"7) 0  0\")    \n",
    "        feedme_list.append(\"8) 0  0\")    \n",
    "        feedme_list.append(f\"9) 0.6 1\") #{galaxy_info[all_col[8]]:.2f} 1\")  # Fixing this to 0.6 to give the arms the best chance to form\n",
    "        #(f\"9) {axis_ratio - 0.3} 1 {gt['9']}\")\n",
    "        feedme_list.append(f\"10) {galaxy_info[all_col[9]]:.2f} 1\") #90  1\") # fixing this to 'normal' 0 so that we can JUST rotate power function\n",
    "        #feedme_list.append(f\"10) 90  1\") # fixing this to 'normal' 0 so that we can JUST rotate power function\n",
    "        feedme_list.append(\"\")\n",
    "    \n",
    "        # Power\n",
    "        feedme_list.append(\"R0) power\")\n",
    "        feedme_list.append(f\"R1) {galaxy_info[all_col[10]]:.2f} 0\") # Chosen based on where *detection* of arms usually start\n",
    "        feedme_list.append(f\"R2) {galaxy_info[all_col[11]]:.2f} 0\")\n",
    "        feedme_list.append(f\"R3) {galaxy_info[all_col[12]]:.2f} 1\") # See calc above\n",
    "        feedme_list.append(f\"R4) {galaxy_info[all_col[13]]:.2f} 1\") # Another good thing to automate via Sparcfire \n",
    "        feedme_list.append(f\"R9) {galaxy_info[all_col[14]]:.2f} 1\") # see if can't 0 this one out... \n",
    "        feedme_list.append(f\"R10) {galaxy_info[all_col[15]]:.2f}  1\")# 40 + pos_angle_power + \" 1\") # Always more to discover, looks like all the images are mirrored across the y axis.\n",
    "\n",
    "        # ---- Fourier modes. May need to add more at some point (?)\n",
    "        feedme_list.append(f\"F1) {galaxy_info[all_col[16]]:.2f} 45  1  1\") # Need to experiment with amplitude and phase angle for better understanding of this\n",
    "        feedme_list.append(f\"F3) {galaxy_info[all_col[17]]:.3f} 25  1  1\")\n",
    "        feedme_list.append(f\"#F4) {galaxy_info[all_col[18]]:.3f} 4  1  1\")\n",
    "        feedme_list.append(f\"#F5) {galaxy_info[all_col[19]]:.3f} 6  1  1\")  \n",
    "        feedme_list.append(\"\")\n",
    "    \n",
    "        # Sky -- Necessary?\n",
    "        feedme_list.append(f\"# Component number: 3\")\n",
    "        feedme_list.append(f\"0) sky\")\n",
    "        feedme_list.append(f\"1) 1000  1\")\n",
    "        feedme_list.append(f\"2) 0  1\")\n",
    "        feedme_list.append(f\"3) 0  1\")\n",
    "                       \n",
    "        count += 1\n",
    "        \n",
    "        formatted_feedme = []\n",
    "        extra = \"\"\n",
    "        for i in feedme_list:\n",
    "            if i and not i.startswith(\"#\"):\n",
    "                str_split = i.split(\")\")\n",
    "                component = extra + str_split[0]\n",
    "                formatted_feedme.append(f\"{i:<{gt['fill']}} {gt[component]}\")\n",
    "                \n",
    "                # Sneakily do this at the end since 0) sky is just component name\n",
    "                if \"sky\" in str_split[1]:\n",
    "                    extra = \"sky\"\n",
    "        #_ = [print(i) for i in formatted_feedme]\n",
    "        #paths_to_feedme.append(write_to_feedme(galaxy, formatted_feedme, feedme_name = gname + \"_input\")) # do I need paths_to_feedme? I used to use it for something...\n",
    "        paths_to_feedme.append(write_to_feedme(pj(top_dir, out_dir, gname), formatted_feedme, feedme_name = gname + \"_xgboost.in\")) # do I need paths_to_feedme? I used to use it for something..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89efbc98-2516-47cb-8e03-d36a1f7ecff3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "update_feedmes(galfit_in_df, top_dir = top_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c99c24-0287-4cb3-8d68-0c2d18385ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # in_notebook() is checked in the export function\n",
    "    export_to_py(\"xgboost_feedme_gen\", output_filename = pj(_MODULE_DIR, \"xgboost_feedme_gen\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
