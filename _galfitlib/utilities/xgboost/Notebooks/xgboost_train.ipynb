{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65604d66-971e-49eb-9cc8-c879435f15ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabs I have open\n",
    "# https://xgboost.readthedocs.io/en/stable/python/examples/multioutput_regression.html#sphx-glr-python-examples-multioutput-regression-py\n",
    "# https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.XGBRegressor\n",
    "# https://xgboost.readthedocs.io/en/stable/parameter.html\n",
    "# https://xgboost.readthedocs.io/en/stable/prediction.html\n",
    "# https://scikit-learn.org/stable/auto_examples/ensemble/plot_random_forest_regression_multioutput.html#sphx-glr-auto-examples-ensemble-plot-random-forest-regression-multioutput-py\n",
    "# https://machinelearningmastery.com/xgboost-for-regression/\n",
    "# https://machinelearningmastery.com/regression-metrics-for-machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99eb61ae-51d7-43e4-b45c-f3f2ecf75804",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade pandas\n",
    "#!pip install graphviz\n",
    "#!pip install xgboost\n",
    "#!pip install hyperopt\n",
    "#!pip install kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff9c70e6-141b-4364-98f8-ef426bf45352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost import XGBClassifier\n",
    "# import xgboost as xgb\n",
    "# from sklearn.model_selection import train_test_split, cross_val_score, RepeatedKFold\n",
    "# from sklearn.metrics import accuracy_score, SCORERS\n",
    "# from sklearn.metrics import mean_squared_error as MSE\n",
    "# #from sklearn.model_selection import GridSearchCV\n",
    "# from hyperopt import fmin, Trials, hp, tpe, STATUS_OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfba9b5d-d601-44fe-a091-5e69955b1dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from scipy.stats import kstest, anderson\n",
    "\n",
    "# from math import ceil\n",
    "# import itertools\n",
    "\n",
    "# from PIL import Image\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# import plotly.graph_objects as go\n",
    "# import plotly.express as px\n",
    "# from plotly.subplots import make_subplots\n",
    "\n",
    "# #import graphviz\n",
    "# import ssl\n",
    "# from glob import glob\n",
    "\n",
    "# #from annoy import AnnoyIndex\n",
    "# import random\n",
    "# import pandas as pd\n",
    "# from scipy import spatial\n",
    "\n",
    "# from shutil import copy2\n",
    "# import json\n",
    "# from copy import deepcopy\n",
    "\n",
    "# import pickle\n",
    "# import argparse\n",
    "\n",
    "# from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45c63468-e491-46a7-bb65-874600bd6187",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For debugging purposes\n",
    "from IPython import get_ipython\n",
    "def in_notebook():\n",
    "    ip = get_ipython()\n",
    "    \n",
    "    if ip:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e81ace0e-098d-4ad4-928a-08fc91ac7e9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import os\n",
    "# from os.path import join as pj\n",
    "\n",
    "# _HOME_DIR = os.path.expanduser(\"~\")\n",
    "# if in_notebook():\n",
    "#     _SPARCFIRE_DIR = pj(_HOME_DIR, \"sparcfire_matt\") \n",
    "#     _MODULE_DIR    = pj(_SPARCFIRE_DIR, \"GalfitModule\")\n",
    "# else:\n",
    "#     try:\n",
    "#         _SPARCFIRE_DIR = os.environ[\"SPARCFIRE_HOME\"]\n",
    "#         _MODULE_DIR = pj(_SPARCFIRE_DIR, \"GalfitModule\")\n",
    "#     except KeyError:\n",
    "#         if __name__ == \"__main__\":\n",
    "#             print(\"SPARCFIRE_HOME is not set. Please run 'setup.bash' inside SpArcFiRe directory if not done so already.\")\n",
    "#             print(\"Checking the current directory for GalfitModule, otherwise quitting.\")\n",
    "            \n",
    "#         _MODULE_DIR = pj(os.getcwd(), \"GalfitModule\")\n",
    "        \n",
    "#         if not exists(_MODULE_DIR):\n",
    "#             raise Exception(\"Could not find GalfitModule!\")\n",
    "    \n",
    "# sys.path.append(_MODULE_DIR)\n",
    "\n",
    "# from Classes.Components import *\n",
    "# from Classes.Containers import *\n",
    "# from Classes.FitsHandlers import *\n",
    "# from Functions.helper_functions import *\n",
    "# from XGBoost.xgboost_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d4fa94-27dd-4ecd-8587-2dd591430aff",
   "metadata": {},
   "source": [
    "#!jupyter nbconvert --to script testing_xgboost.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84028970-8f3a-433f-a70e-ec9df5e20969",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Force >python 3.10 for various compatabilities\n",
    "    out_str = \"\\t Python3.10 or greater required! Exitting without generating feedmes...\"\n",
    "    assert sys.version_info >= (3, 10), out_str\n",
    "    \n",
    "    cwd = absp(os.getcwd()) # Doesn't work *in* notebook\n",
    "    old_cwd = absp(cwd) # Strings are immutable\n",
    "    \n",
    "    username = os.environ[\"USER\"]\n",
    "    \n",
    "    USAGE = f\"\"\"USAGE:\n",
    "\n",
    "    python3 ./{sys.argv[0]} [OPTION] [[RUN-DIRECTORY] IN-DIRECTORY TMP-DIRECTORY OUT-DIRECTORY]\n",
    "    \n",
    "    OPTIONS => [-v | --verbose]\n",
    "\n",
    "    This script is used to train XGBoost to feed better input to GALFIT via SpArcFiRe. \n",
    "    By default, it runs from the RUN (or current) directory and uses the\n",
    "    '-in' '-tmp' and '-out' directories as specified or otherwise defaults to \n",
    "    'sparcfire-in', 'sparcfire-tmp', 'sparcfire-out'. \n",
    "\n",
    "    Please do not specify symlinks for the above, they discomfort the programmer.\n",
    "    \"\"\"\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description = USAGE)\n",
    "    \n",
    "    parser.add_argument('-v', '--verbose',\n",
    "                        dest     = 'verbose', \n",
    "                        action   = 'store_const',\n",
    "                        const    = True,\n",
    "                        default  = False,\n",
    "                        help     = 'Verbose output for all bash commands in control script.'\n",
    "                       )\n",
    "    \n",
    "    parser.add_argument(dest     = 'out_path',\n",
    "                        action   = 'store',\n",
    "                        type     = str,\n",
    "                        help     = \"[OUT-DIRECTORY] from SpArcFiRe. \\\n",
    "                                    SpArcFiRe directories should follow -in, -tmp, -out.\"\n",
    "                       )\n",
    "    \n",
    "    if not in_notebook():\n",
    "        args              = parser.parse_args() # Using vars(args) will call produce the args as a dict\n",
    "        \n",
    "        verbose           = args.verbose\n",
    "        capture_output    = not args.verbose\n",
    "        \n",
    "        sparc_out_dir = args.out_path\n",
    "            \n",
    "    else:\n",
    "        verbose = False\n",
    "        capture_output = True\n",
    "        \n",
    "        cwd = cwd.replace(\"ics-home\", username)\n",
    "        sparc_out_dir = pj(_HOME_DIR, \"run2_1000_galfit\", \"sparcfire-out\") #pj(cwd, \"sparcfire-out\")\n",
    "        \n",
    "        sys.path.append(pj(_HOME_DIR, \".local\", \"bin\"))\n",
    "        \n",
    "    # Making these absolute paths\n",
    "    cwd     = absp(cwd)\n",
    "    #in_dir  = absp(in_dir)\n",
    "    #tmp_dir = absp(tmp_dir)\n",
    "    sparc_out_dir = absp(sparc_out_dir)\n",
    "    \n",
    "    # Changing to specified working dir\n",
    "    os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1814091a-49d0-48c9-a599-42799d5c956a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    png_tiled_dir  = pj(cwd, \"labeled_png_out\")\n",
    "    good_labeled_dir  = pj(png_tiled_dir, \"good\")\n",
    "\n",
    "    inputs_dir = pj(cwd, \"galfit_inputs\")\n",
    "    good_inputs_dir = pj(inputs_dir, \"good\")\n",
    "    not_good_inputs_dir = pj(inputs_dir, \"not_good\")\n",
    "\n",
    "    outputs_dir = pj(cwd, \"galfit_outputs\")\n",
    "    good_outputs_dir = pj(outputs_dir, \"good\")\n",
    "    not_good_outputs_dir = pj(outputs_dir, \"not_good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d53c4b9-8d53-444c-b6f8-368eaddc9a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Used to get organized\n",
    "# def generate_labels_from_imgs(all_galaxies_path, good_folder_path):\n",
    "    \n",
    "#     # good galaxies are named ###_combined.png\n",
    "#     # inputs are named ###.in\n",
    "    \n",
    "#     good_galaxy_names = list(map(lambda i: i.split(\"_\")[0], os.listdir(good_folder_path)))\n",
    "#     all_galaxy_names = [os.path.basename(i) for i in os.listdir(all_galaxies_path) if os.path.basename(i).startswith(\"123\")]\n",
    "    \n",
    "#     label_dict = {i:(1 if i in good_galaxy_names else 0) for i in all_galaxy_names}\n",
    "    \n",
    "#     return label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "379b13f2-b2c3-4008-af41-d1fd17fe997f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def organize_files(label_dict, sparcfire_out_dir, **kwargs):\n",
    "    \n",
    "#     labels_top_dir  = kwargs.get(\"labels_top_dir\", os.getcwd())\n",
    "#     good_name       = kwargs.get(\"good_name\", \"good\")\n",
    "#     not_good_name   = kwargs.get(\"not_good_name\", \"not_good\")\n",
    "#     label_dump_path = kwargs.get(\"label_dump_path\", pj(labels_top_dir, \"labeled_galaxies.json\"))\n",
    "    \n",
    "#     temp_dict = deepcopy(label_dict)\n",
    "#     for gname, label in temp_dict.items():\n",
    "#         if label:\n",
    "#             label_name = good_name\n",
    "#         else:\n",
    "#             label_name = not_good_name\n",
    "        \n",
    "#         # We will extract feedme from output fits file\n",
    "#         # There should always be a generated output (because labeled) but just in case...\n",
    "#         # Copy that first so the except catches before trying to copy the input that way we don't have a mismatch\n",
    "#         try:\n",
    "#             #copy2(pj(sparcfire_out_dir, gname, f\"{gname}_galfit_out.fits\"), pj(labels_top_dir, \"galfit_outputs\", label_name))\n",
    "#             #copy2(pj(sparcfire_out_dir, gname, f\"{gname}.in\"), pj(labels_top_dir, \"galfit_inputs\", label_name))\n",
    "#             copy2(pj(sparcfire_out_dir, gname, f\"{gname}_out.fits\"), pj(labels_top_dir, \"galfit_outputs\", label_name, f\"{gname}_galfit_out.fits\"))\n",
    "#             copy2(pj(sparcfire_out_dir, gname, \"autogen_feedme_galfit.in\"), pj(labels_top_dir, \"galfit_inputs\", label_name, f\"{gname}.in\"))\n",
    "#         except FileNotFoundError:\n",
    "#             print(f\"No output found for {gname}, continuing to copy...\")\n",
    "#             label_dict.pop(gname)\n",
    "            \n",
    "#     with open(label_dump_path, \"w\") as lg:\n",
    "#         json.dump(label_dict, lg)\n",
    "    \n",
    "#     return label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4825f8ec-a2b6-463b-a5d6-15630fa85648",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    label_json = pj(cwd, 'labeled_galaxies.json')\n",
    "    \n",
    "    if exists(label_json):\n",
    "        label_dict = json.load(open(label_json, 'r'))\n",
    "    else:\n",
    "        label_dict = generate_labels_from_imgs(sparc_out_dir, good_labeled_dir)\n",
    "        label_dict = organize_files(label_dict, pj(_HOME_DIR, \"run2_1000_galfit\", \"sparcfire-out\"), label_dump_path = label_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6528c485-d5d8-4675-8660-2b229f39ade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LabeledModel(OutputFits):\n",
    "#     def __init__(self, \n",
    "#                  filepath = \"\",\n",
    "#                  label = 0,\n",
    "#                  **kwargs\n",
    "#                 ):\n",
    "        \n",
    "#         OutputFits.__init__(self, filepath)\n",
    "        \n",
    "#         self.label = label        \n",
    "#         self.df    = self.feedme.to_pandas(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75f57399-5351-49f8-b88e-b6005afffbdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Non-parallelized\n",
    "# def build_df(label_dict, label_dirs, file_suffix: str):\n",
    "    \n",
    "#     out_df = pd.DataFrame()\n",
    "    \n",
    "#     for gname, label in label_dict.items():\n",
    "\n",
    "#         # 0 bad, 1 good\n",
    "#         if label == 0:\n",
    "#             input_dir = label_dirs[0]\n",
    "#             #str_label = \"not_good\"\n",
    "#         else:\n",
    "#             input_dir = label_dirs[1]\n",
    "#             #str_label = \"good\"\n",
    "\n",
    "#         #gal_dict, param_names = #galfit_param_grab(pj(input_dir, gname + file_suffix))\n",
    "# #         if not param_names: continue\n",
    "        \n",
    "# #         for i, param in enumerate(param_names):\n",
    "# #             if param in param_names[:i]:\n",
    "# #                 param += \"\"\n",
    "\n",
    "#         #gname_df = flatten_to_pandas(gal_dict, param_names, gname)\n",
    "#         path_to_output = pj(input_dir, f\"{gname}{file_suffix}\")\n",
    "        \n",
    "#         if file_suffix.endswith(\".fits\"):\n",
    "#             feedme = OutputFits(path_to_output).feedme\n",
    "#             gname_df = feedme.to_pandas()\n",
    "            \n",
    "#             region_to_fit = feedme.header.region_to_fit\n",
    "#             gname_df[\"crop_rad\"] = region_to_fit[1] - region_to_fit[0]\n",
    "            \n",
    "#         elif file_suffix.endswith(\".in\"):\n",
    "#             feedme = FeedmeContainer(path_to_feedme = path_to_output)\n",
    "#             feedme.from_file(path_to_output)\n",
    "#             gname_df = feedme.to_pandas()\n",
    "            \n",
    "#             region_to_fit = feedme.header.region_to_fit\n",
    "#             gname_df[\"crop_rad\"] = region_to_fit[1] - region_to_fit[0]\n",
    "            \n",
    "#         gname_df[\"label\"] = label #str_label\n",
    "#         # TODO: Put this rename function in a to_pandas() function of OutputFits\n",
    "#         # Make note in documentation: name is incoherent in everything but an outputfits\n",
    "#         # since a feedme does not necessarily imply a galaxy\n",
    "#         # That being said, make an optional gname parameter in feedme\n",
    "#         gname_df.rename(index = {0:gname}, inplace = True)\n",
    "#         out_df = pd.concat([out_df, gname_df])\n",
    "\n",
    "#     # For the input galaxies, we have a lot of held values, these are uneccessary\n",
    "#     # https://stackoverflow.com/a/39658662\n",
    "#     nunique = out_df.nunique()\n",
    "#     cols_to_drop = nunique[nunique == 1].index\n",
    "#     out_df.drop(columns = cols_to_drop, inplace = True)\n",
    "    \n",
    "#     return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f658f6b4-c4b0-4d5e-8066-7355885eed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_df(gname, label, count, label_dirs, file_suffix: str):\n",
    "    \n",
    "#     if not count % 100:\n",
    "#         print(gname, count)\n",
    "        \n",
    "#     # 0 bad, 1 good\n",
    "#     if label == 0:\n",
    "#         input_dir = label_dirs[0]\n",
    "#         #str_label = \"not_good\"\n",
    "#     else:\n",
    "#         input_dir = label_dirs[1]\n",
    "#         #str_label = \"good\"\n",
    "\n",
    "#     #gal_dict, param_names = #galfit_param_grab(pj(input_dir, gname + file_suffix))\n",
    "# #         if not param_names: continue\n",
    "\n",
    "# #         for i, param in enumerate(param_names):\n",
    "# #             if param in param_names[:i]:\n",
    "# #                 param += \"\"\n",
    "\n",
    "#     #gname_df = flatten_to_pandas(gal_dict, param_names, gname)\n",
    "#     path_to_output = pj(input_dir, f\"{gname}{file_suffix}\")\n",
    "\n",
    "#     if file_suffix.endswith(\".fits\"):\n",
    "#         feedme = OutputFits(path_to_output).feedme\n",
    "#         gname_df = feedme.to_pandas()\n",
    "\n",
    "#         region_to_fit = feedme.header.region_to_fit\n",
    "#         gname_df[\"crop_rad\"] = region_to_fit[1] - region_to_fit[0]\n",
    "\n",
    "#     elif file_suffix.endswith(\".in\"):\n",
    "#         feedme = FeedmeContainer(path_to_feedme = path_to_output)\n",
    "#         feedme.from_file(path_to_output)\n",
    "#         gname_df = feedme.to_pandas()\n",
    "\n",
    "#         region_to_fit = feedme.header.region_to_fit\n",
    "#         gname_df[\"crop_rad\"] = region_to_fit[1] - region_to_fit[0]\n",
    "\n",
    "#     gname_df[\"label\"] = label #str_label\n",
    "#     # TODO: Put this rename function in a to_pandas() function of OutputFits\n",
    "#     # Make note in documentation: name is incoherent in everything but an outputfits\n",
    "#     # since a feedme does not necessarily imply a galaxy\n",
    "#     # That being said, make an optional gname parameter in feedme\n",
    "#     gname_df.rename(index = {0:gname}, inplace = True)\n",
    "    \n",
    "#     return gname_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64bbf2c2-77a2-4ca8-bd78-c760ab2a129b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def convert_angles(in_df, **kwargs):\n",
    "#     angles = [\"position_angle_sersic_1\",\n",
    "#               \"position_angle_sersic_2\",\n",
    "#               \"cumul_rot_power_2\",\n",
    "#               \"inclination_power_2\",\n",
    "#               \"sky_position_angle_power_2\"]\n",
    "    \n",
    "#     angles = kwargs.get(\"angles\", angles)\n",
    "    \n",
    "#     out_df = in_df.copy()\n",
    "    \n",
    "#     for col_name in angles:\n",
    "#         if col_name in out_df.columns:\n",
    "#             # Take advantage of symmetry across axes\n",
    "#             # Will have to be careful when outputting new template to retain correct direction\n",
    "#             # will likely pull this from original data\n",
    "#             out_df.loc[out_df[col_name] < 0, col_name] += 180\n",
    "#             out_df[col_name] *= np.pi/180\n",
    "            \n",
    "#     return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73a11bb7-07c0-4972-8ff8-5cb0495a35bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def prepare_df(picklepath, label_dict, label_dirs, file_suffix):\n",
    "#     if exists(picklepath):\n",
    "#         df = pickle.load(open(picklepath, \"rb\"))\n",
    "#     else:\n",
    "#         if file_suffix.endswith(\".fits\"):\n",
    "#             df = Parallel(n_jobs = -2, timeout = 30)(\n",
    "#             delayed(build_df)(\n",
    "#                               gname,\n",
    "#                               label,\n",
    "#                               count,\n",
    "#                               label_dirs=label_dirs, \n",
    "#                               file_suffix=\"_galfit_out.fits\"\n",
    "#                              ) \n",
    "#             for count, (gname, label) in enumerate(label_dict.items())\n",
    "#                                                     )\n",
    "#         elif file_suffix.endswith(\".in\"):\n",
    "#             df = [build_df(gname, label, count, label_dirs, file_suffix) \n",
    "#                   for count, (gname, label) in enumerate(label_dict.items())]   \n",
    "            \n",
    "#         else:\n",
    "#             raise Exception(f\"file suffix {file_suffix} not valid.\")\n",
    "        \n",
    "#         df = pd.concat(df)\n",
    "        \n",
    "#         # For the input galaxies, we have a lot of held values, these are uneccessary\n",
    "#         # https://stackoverflow.com/a/39658662\n",
    "#         nunique = df.nunique()\n",
    "#         cols_to_drop = nunique[nunique == 1].index\n",
    "#         df.drop(columns = cols_to_drop, inplace = True)\n",
    "        \n",
    "#         df.to_pickle(picklepath)\n",
    "\n",
    "#     # Save *before* conversion for data posterity\n",
    "#     df = convert_angles(df)\n",
    "    \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1e89dd4-5ce5-4f3a-828c-999bdf915b2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grabbing GALFIT input data...\n",
      "Done!\n",
      "\n",
      "Grabbing GALFIT output data, this may take awhile (if not already saved)...\n",
      "Done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"Grabbing GALFIT input data...\")\n",
    "    galfit_in_df = prepare_df(\"galfit_in_df.pkl\", label_dict, [not_good_inputs_dir, good_inputs_dir], \".in\")\n",
    "    print(\"Done!\\n\")\n",
    "    \n",
    "    print(\"Grabbing GALFIT output data, this may take awhile (if not already saved)...\")\n",
    "    galfit_out_df = prepare_df(\"galfit_out_df.pkl\", label_dict, [not_good_outputs_dir, good_outputs_dir], \"_galfit_out.fits\")\n",
    "    print(\"Done!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04dac6a6-337d-4bbf-ad4c-44853be94aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     in_pkl = pj(cwd, \"galfit_in_df.pkl\")\n",
    "#     if exists(in_pkl):\n",
    "#         galfit_in_df = pickle.load(open(in_pkl, \"rb\"))\n",
    "#     else:   \n",
    "#         galfit_in_df = [build_df(gname, label, count, [not_good_inputs_dir, good_inputs_dir], \".in\") \n",
    "#                         for count, (gname, label) in enumerate(label_dict.items())]   \n",
    "        \n",
    "#         galfit_in_df = pd.concat(galfit_in_df)\n",
    "        \n",
    "#         # For the input galaxies, we have a lot of held values, these are uneccessary\n",
    "#         # https://stackoverflow.com/a/39658662\n",
    "#         nunique = galfit_in_df.nunique()\n",
    "#         cols_to_drop = nunique[nunique == 1].index\n",
    "#         galfit_in_df.drop(columns = cols_to_drop, inplace = True)\n",
    "        \n",
    "#         galfit_in_df.to_pickle(in_pkl)\n",
    "        \n",
    "#     galfit_in_df = convert_angles(galfit_in_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "607ff169-cddf-4ed3-a45b-0ad446754923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: Parallelize this since FITS take so much longer\n",
    "# # I could alternatively output all the .in files from those FITS files separate and then build the DFs... a thought\n",
    "# if __name__ == \"__main__\":\n",
    "#     out_pkl = pj(cwd, \"galfit_out_df.pkl\")\n",
    "#     if exists(out_pkl):\n",
    "#         galfit_out_df = pickle.load(open(out_pkl, \"rb\"))\n",
    "#     else:\n",
    "#         galfit_out_df = Parallel(n_jobs = -2, timeout = 30)(\n",
    "#             delayed(parallel_build_df)(\n",
    "#                                        gname,\n",
    "#                                        label,\n",
    "#                                        count,\n",
    "#                                        label_dirs=[not_good_outputs_dir, good_outputs_dir], \n",
    "#                                        file_suffix=\"_galfit_out.fits\"\n",
    "#                                       ) \n",
    "#             for count, (gname, label) in enumerate(label_dict.items())\n",
    "#                                                                            )\n",
    "#         galfit_out_df = pd.concat(galfit_out_df)\n",
    "        \n",
    "#         # For the input galaxies, we have a lot of held values, these are uneccessary\n",
    "#         # https://stackoverflow.com/a/39658662\n",
    "#         nunique = galfit_out_df.nunique()\n",
    "#         cols_to_drop = nunique[nunique == 1].index\n",
    "#         galfit_out_df.drop(columns = cols_to_drop, inplace = True)\n",
    "        \n",
    "#         galfit_out_df.to_pickle(out_pkl)\n",
    "        \n",
    "#     galfit_out_df = convert_angles(galfit_out_df)\n",
    "#     #galfit_out_df['crop_rad'] = galfit_in_df['crop_rad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb439fc5-9c8f-4fa4-8692-981e4d4560fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check deprecated then delete\n",
    "# positions = [\"position_x_sersic_1\",\n",
    "#              \"position_y_sersic_1\",\n",
    "#              \"position_x_sersic_2\",\n",
    "#              \"position_y_sersic_2\"]\n",
    "\n",
    "# fourier = [\"F1_amplitude_fourier_2\",\n",
    "#            \"F1_phase_angle_fourier_2\",\n",
    "#            \"F3_amplitude_fourier_2\",\n",
    "#            \"F3_phase_angle_fourier_2\"\n",
    "#           ]\n",
    "\n",
    "# file_prefixes = [\"reduced_galfit_in\", \"reduced_galfit_out\"]\n",
    "# ignore_galfit_in  = [\"inner_rad_power_2\"]\n",
    "# ignore_galfit_in.extend(positions)\n",
    "# ignore_galfit_in.extend(fourier)\n",
    "\n",
    "# ignore_galfit_out = [\"crop_rad\",\n",
    "#                      \"effective_radius_sersic_1\", # Bulge radius goes crazzyyyyyy\n",
    "#                      \"inclination_power_2\", # Trust sparc/galfit on this one\n",
    "#                      \"inner_rad_power_2\",\n",
    "#                      \"outer_rad_power_2\",\n",
    "#                      \"sky_background_sky_3\", # Trust galfit on this one\n",
    "#                      \"dsky_dx_sky_3\", # if we include them, does it get better? for future testing\n",
    "#                      \"dsky_dy_sky_3\"\n",
    "#                     ]\n",
    "# ignore_galfit_out.extend(positions)\n",
    "# ignore_galfit_out.extend(fourier)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# in_filter = []\n",
    "# # filter_1 = \"sersic_index_sersic_1\"\n",
    "# # filter_2 = \"sersic_index_sersic_1\"\n",
    "# # filter_3 = \"magnitude_sersic_1\"\n",
    "# # filter_4 = \"effective_radius_sersic_1\"\n",
    "# # filter_5 = \"effective_radius_sersic_2\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb03153d-6dea-45b4-9275-c6c828adbd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def export_filter():\n",
    "#     positions = [\"position_x_sersic_1\",\n",
    "#                  \"position_y_sersic_1\",\n",
    "#                  \"position_x_sersic_2\",\n",
    "#                  \"position_y_sersic_2\"]\n",
    "\n",
    "#     fourier = [\"F1_amplitude_fourier_2\",\n",
    "#                \"F1_phase_angle_fourier_2\",\n",
    "#                \"F3_amplitude_fourier_2\",\n",
    "#                \"F3_phase_angle_fourier_2\"\n",
    "#               ]\n",
    "    \n",
    "#     # Not all df may have columns I'd otherwise check\n",
    "#     # For instance, I hold the input constant for some variables (sersic index) so the input\n",
    "#     # df won't have those columns. So be careful here\n",
    "#     ignore_galfit_in  = [\"inner_rad_power_2\"]\n",
    "#     ignore_galfit_in.extend(positions)\n",
    "#     ignore_galfit_in.extend(fourier)\n",
    "    \n",
    "#     ignore_galfit_out = [\"crop_rad\",\n",
    "#                          \"effective_radius_sersic_1\", # Bulge radius goes crazzyyyyyy\n",
    "#                          \"inclination_power_2\", # Trust sparc/galfit on this one\n",
    "#                          \"inner_rad_power_2\",\n",
    "#                          \"outer_rad_power_2\",\n",
    "#                          \"F1_amplitude_fourier_2\",\n",
    "#                          \"F3_amplitude_fourier_2\",\n",
    "#                          \"F1_phase_angle_fourier_2\",\n",
    "#                          \"F3_phase_angle_fourier_2\",\n",
    "#                          \"sky_background_sky_3\", # Trust galfit on this one\n",
    "#                          \"dsky_dx_sky_3\", # if we include them, does it get better? for future testing\n",
    "#                          \"dsky_dy_sky_3\"\n",
    "#                         ]\n",
    "#     ignore_galfit_out.extend(positions)\n",
    "#     ignore_galfit_out.extend(fourier)\n",
    "\n",
    "#     in_filter = []\n",
    "    \n",
    "#     out_filter = [#\"`Asymptotic spiral powerlaw disk` <= 1\",\n",
    "#               f\"`sersic_index_sersic_1` > 14\",\n",
    "#               f\"`sersic_index_sersic_1` < 0.05\",\n",
    "#               f\"`magnitude_sersic_1` > 26\",\n",
    "#               f\"`effective_radius_sersic_1` > `crop_rad`\",\n",
    "#               f\"`effective_radius_sersic_2` > `crop_rad`\"\n",
    "#               #\"`R_e (effective radius)   (pix) bulge` < `Crop Rad`\"\n",
    "#               ]\n",
    "    \n",
    "#     return ignore_galfit_in, ignore_galfit_out, in_filter, out_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72c72bfb-04f8-48f0-9cc9-6423712b15f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # in_train/test should always have fewer exclusions and those exclusions must also be in the out_train/test\n",
    "    # so that the algo isn't predicting things sight unseen\n",
    "    sklearn = True\n",
    "\n",
    "    ignore_galfit_in, ignore_galfit_out, in_filter, out_filter = export_filter()\n",
    "    \n",
    "    file_prefixes = [\"reduced_galfit_in\", \"reduced_galfit_out\"]\n",
    "    \n",
    "    ignore_galfit = (ignore_galfit_in, ignore_galfit_out)\n",
    "    col_ignore = {fp:ig for fp, ig in zip(file_prefixes, ignore_galfit)}\n",
    "    \n",
    "    filter_strings = (in_filter, out_filter)\n",
    "    gal_filter = {fp:fs for fp, fs in zip(file_prefixes, filter_strings)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3dbcaf11-c6f0-4e63-8504-9d74c3549b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Per https://xgboost.readthedocs.io/en/stable/python/python_intro.html\n",
    "# # For training *regressor* on good data\n",
    "# def split_save_df_reg(*args, file_prefixes = [], col_ignore = {}, gal_filter = {}, sklearn = False):\n",
    "#     # col_ignore must be list of list of columns since we drop different things for different df\n",
    "#     # gal_filter must be given as: `column name` cond value, i.e. \"`Asymptotic spiral powerlaw disk` <= 1\"\n",
    "#     # Note, the conditions are what we *don't want*\n",
    "    \n",
    "#     assert len(file_prefixes) == len(args), \"File prefixes must be same length as # of dataframes being passed in! Try again\"\n",
    "#     #assert col_ignore == len(args), \"col_ignore must be same length as # of dataframes being passed in! Try again\"\n",
    "    \n",
    "#     return_dict = {}\n",
    "    \n",
    "#     # Specifically looking for good galaxies since we're not classifying\n",
    "#     #gal_filter.append(\"label != 1\") \n",
    "#     #gal_filter = \" or \".join(gal_filter)\n",
    "    \n",
    "#     galaxies_to_drop = [in_df.query(\n",
    "#                                     \" or \".join(gf + [\"label != 1\"])\n",
    "#                                     ).index \n",
    "#                         for in_df, gf in zip(args, gal_filter.values()) if gf]\n",
    "    \n",
    "#     # Unpacking to keep the list comp ;)\n",
    "#     galaxies_to_drop = list(itertools.chain.from_iterable(galaxies_to_drop))\n",
    "#     print(f\"Keeping {len(args[0]) - len(galaxies_to_drop)} galaxies (out of {len(args[0].query('label == 1'))})\")\n",
    "    \n",
    "#     for in_df, file_prefix in zip(args, file_prefixes):\n",
    "#         # Filter and exclude\n",
    "        \n",
    "#         exclude = ['label'] + col_ignore.get(file_prefix, [])\n",
    "        \n",
    "#         exclude = list(set(exclude).intersection(set(in_df.columns)))\n",
    "#         in_df_good = in_df.drop(index = galaxies_to_drop, columns = exclude)\n",
    "        \n",
    "#         label = pd.DataFrame(np.ones(len(in_df_good)), columns = [\"label\"], dtype = \"int\")\n",
    "            \n",
    "#         # Pass random_state = 0 to guarantee input and output are lined up\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(in_df_good, label, test_size=.3, random_state = 0)\n",
    "    \n",
    "# #         dtrain = xgb.DMatrix(X_train, label = y_train)\n",
    "# #         dtest  = xgb.DMatrix(X_test,  label = y_test)\n",
    "# #         ddata  = xgb.DMatrix(in_df_good, label = label)\n",
    "\n",
    "# #         print(f\"Saving dmatrices to file: {file_prefix}.train/test/data\")\n",
    "# #         dtrain.save_binary(f'{file_prefix}.train')\n",
    "# #         dtest.save_binary(f'{file_prefix}.test')\n",
    "# #         ddata.save_binary(f'{file_prefix}.data')\n",
    "        \n",
    "#         in_df_good[\"label\"] = list(label.label)\n",
    "#         if sklearn:\n",
    "#             return_dict[file_prefix] = X_train, X_test, y_train, y_test, in_df_good\n",
    "#         else:\n",
    "#             return_dict[file_prefix] = dtrain, dtest, ddata, in_df_good, label\n",
    "\n",
    "#     return return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07e7d562-2a85-402b-830b-9b25e4d8ae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: FILTER OUT PREVIOUS GALFIT RESULTS FOR NON-PHYSICAL DATA, I.E. SERSIC INDEX TOO HIGH OR TOO LOW IN GOOD DATA\n",
    "# Convert angles to radians -- done\n",
    "# weight spiral law(?), look up how weighting works -- doesn't work\n",
    "# Make better plots (seaborn?)\n",
    "# Use physics based constraints to filter results\n",
    "# Determine better loss method? Hmmmmm https://stats.stackexchange.com/a/445454\n",
    "# For +/- things (like angle) find some way to use absolute value while retaining distribution, see if that makes things better -- done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad28c5c7-1e56-4faa-b0b0-a4179c8cf621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keeping 261 galaxies (out of 304)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    split_save_out = split_save_df_reg(\n",
    "                                       galfit_in_df, galfit_out_df,\n",
    "                                       file_prefixes = file_prefixes,\n",
    "                                       col_ignore    = col_ignore,\n",
    "                                       gal_filter    = gal_filter,\n",
    "                                       sklearn       = sklearn\n",
    "                                      )\n",
    "\n",
    "    # New...df is a combo of train/test, no different otherwise\n",
    "    in_train,  in_test,  _, _, new_in_df    = split_save_out[file_prefixes[0]]\n",
    "    out_train, out_test, _, _, new_out_df   = split_save_out[file_prefixes[1]]\n",
    "\n",
    "    # Could train on bad galaxies too... but only for classification purposes\n",
    "    \n",
    "    assert len(galfit_out_df) - len(galfit_out_df.query(\" or \".join(out_filter + [\"label != 1\"]))) == len(new_out_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2e3313c-1c59-43cb-a277-5c68610a23fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_data(file_prefix):\n",
    "#     dtrain = xgb.DMatrix(f'{file_prefix}.train')\n",
    "#     dtest  = xgb.DMatrix(f'{file_prefix}.test')\n",
    "#     ddata  = xgb.DMatrix(f'{file_prefix}.data')\n",
    "    \n",
    "#     return dtrain, dtest, ddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa01f715-0e93-4fca-9736-e35555347b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     if not sklearn:\n",
    "#         dtrain_in, dtest_in, ddata_in = load_data(file_prefixes[0])\n",
    "#         dtrain_out, dtest_out, ddata_out = load_data(file_prefixes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ef6e963-6563-4ddb-84e6-48d60ec8d6cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def loss_methods(test_df, pred_df, method = \"kstest\"):\n",
    "#     method = method.lower()\n",
    "    \n",
    "#     if method == \"kstest\":\n",
    "#         loss = np.average([kstest(test_df[col].values, pred_df[col].values).statistic\n",
    "#                                       for col in pred_df])\n",
    "#         method_str = \"KStest Stat\"\n",
    "\n",
    "\n",
    "#     elif method == \"rmse\":\n",
    "#         # squared = False gives RMSE\n",
    "#         loss = MSE(test_df, pred_df, squared = False)\n",
    "#         method_str = \"RMSE\"\n",
    "        \n",
    "#     # Average of per galaxy rmse\n",
    "#     elif method == \"galaxy_rmse\":\n",
    "#         comparison_df = np.square(test_df - pred_df)\n",
    "#         loss = np.mean(np.sqrt(comparison_df.mean(axis=1)))\n",
    "#         method_str = \"Per Galaxy RMSE\"\n",
    "        \n",
    "#     print(f\"Average {method_str}: {loss:.3f}\")\n",
    "\n",
    "#     return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ddb1043-7594-4e46-ac66-4f24cc86ab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Objective function\n",
    "# def objective(space): #, data, label, test_size = 0.3):\n",
    "#     clf = xgb.XGBRegressor(\n",
    "#                     learning_rate = space['learning_rate'],\n",
    "#                     n_estimators = space['n_estimators'],\n",
    "#                     #subsample = space['subsample'],\n",
    "#                     max_depth = int(space['max_depth']))\n",
    "#                     #gamma = space['min_split_loss'])\n",
    "#                     #reg_alpha = int(space['reg_alpha']),\n",
    "#                     #min_child_weight=int(space['min_child_weight']),\n",
    "#                     #colsample_bytree=int(space['colsample_bytree']))\n",
    "    \n",
    "#     clf.set_params(#eval_metric=\"auc\",\n",
    "#                    tree_method = \"hist\",\n",
    "#                    early_stopping_rounds=10,\n",
    "#                    objective='reg:squarederror'\n",
    "#                    #objective='reg:pseudohubererror'\n",
    "#                    #'eval_metric' : 'error' # Binary classification error rate\n",
    "#                    )\n",
    "    \n",
    "#     clf.fit(in_train, \n",
    "#             out_train, \n",
    "#             eval_set = [(in_train, out_train)],\n",
    "#             verbose = False)\n",
    "\n",
    "#     pred = clf.predict(in_test)\n",
    "#     out_pred_df = pd.DataFrame(pred, columns = out_test.columns, index = in_test.index)\n",
    "\n",
    "#     # use weights to lower contribution from values with wider spread since these aren't all normalized\n",
    "#     # alternatively normalize everything to [0,1]\n",
    "#     #rmse = np.sqrt(MSE(out_test, pred))#, multioutput = \"raw_values\"))\n",
    "#     #print(f\"RMSE: {rmse:.3f}\")\n",
    "    \n",
    "# #     acc = []\n",
    "# #     for col in out_test:\n",
    "# #         acc.append(kstest(out_test[col].values, out_pred_df[col].values).statistic)\n",
    "        \n",
    "# #     print(np.average(acc))\n",
    "        \n",
    "#     loss = loss_methods(out_test, out_pred_df, method = \"kstest\")\n",
    "    \n",
    "#     return {'loss': loss, 'status': STATUS_OK }\n",
    "#     #accuracy = accuracy_score(y_test, pred>0.5)\n",
    "#     #print (f\"SCORE: {accuracy:.3f}\")\n",
    "#     #return {'loss': -accuracy, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c76a6a62-06ab-4841-8f8a-390b42749e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average KStest Stat: 0.362                             \n",
      "Average KStest Stat: 0.278                                                       \n",
      "Average KStest Stat: 0.207                                                        \n",
      "Average KStest Stat: 0.200                                                        \n",
      "Average KStest Stat: 0.222                                                        \n",
      "Average KStest Stat: 0.437                                                        \n",
      "Average KStest Stat: 0.234                                                        \n",
      "Average KStest Stat: 0.216                                                        \n",
      "Average KStest Stat: 0.393                                                        \n",
      "Average KStest Stat: 0.205                                                        \n",
      "Average KStest Stat: 0.289                                                         \n",
      "Average KStest Stat: 0.212                                                         \n",
      "Average KStest Stat: 0.320                                                         \n",
      "Average KStest Stat: 0.265                                                         \n",
      "Average KStest Stat: 0.276                                                         \n",
      "Average KStest Stat: 0.206                                                         \n",
      "Average KStest Stat: 0.416                                                         \n",
      "Average KStest Stat: 0.442                                                         \n",
      "Average KStest Stat: 0.217                                                         \n",
      "Average KStest Stat: 0.227                                                         \n",
      "Average KStest Stat: 0.216                                                         \n",
      "Average KStest Stat: 0.205                                                         \n",
      "Average KStest Stat: 0.204                                                         \n",
      "Average KStest Stat: 0.206                                                         \n",
      "Average KStest Stat: 0.204                                                         \n",
      "Average KStest Stat: 0.204                                                         \n",
      "Average KStest Stat: 0.199                                                         \n",
      "Average KStest Stat: 0.212                                                         \n",
      "Average KStest Stat: 0.207                                                         \n",
      "Average KStest Stat: 0.214                                                         \n",
      "Average KStest Stat: 0.222                                                         \n",
      "Average KStest Stat: 0.205                                                         \n",
      "Average KStest Stat: 0.306                                                         \n",
      "Average KStest Stat: 0.208                                                         \n",
      "Average KStest Stat: 0.487                                                         \n",
      "Average KStest Stat: 0.205                                                         \n",
      "Average KStest Stat: 0.210                                                         \n",
      "Average KStest Stat: 0.293                                                         \n",
      "Average KStest Stat: 0.206                                                         \n",
      "Average KStest Stat: 0.318                                                         \n",
      "Average KStest Stat: 0.247                                                         \n",
      "Average KStest Stat: 0.207                                                         \n",
      "Average KStest Stat: 0.209                                                         \n",
      "Average KStest Stat: 0.592                                                         \n",
      "Average KStest Stat: 0.209                                                         \n",
      "Average KStest Stat: 0.259                                                         \n",
      "Average KStest Stat: 0.208                                                         \n",
      "Average KStest Stat: 0.223                                                         \n",
      "Average KStest Stat: 0.244                                                         \n",
      "Average KStest Stat: 0.306                                                         \n",
      "Average KStest Stat: 0.210                                                         \n",
      "Average KStest Stat: 0.213                                                         \n",
      "Average KStest Stat: 0.216                                                         \n",
      "Average KStest Stat: 0.212                                                         \n",
      "Average KStest Stat: 0.224                                                         \n",
      "Average KStest Stat: 0.688                                                         \n",
      "Average KStest Stat: 0.199                                                         \n",
      "Average KStest Stat: 0.332                                                         \n",
      "Average KStest Stat: 0.216                                                         \n",
      "Average KStest Stat: 0.199                                                         \n",
      "Average KStest Stat: 0.197                                                         \n",
      "Average KStest Stat: 0.213                                                         \n",
      "Average KStest Stat: 0.207                                                        \n",
      "Average KStest Stat: 0.201                                                        \n",
      "Average KStest Stat: 0.200                                                        \n",
      "Average KStest Stat: 0.196                                                        \n",
      "Average KStest Stat: 0.200                                                         \n",
      "Average KStest Stat: 0.205                                                         \n",
      "Average KStest Stat: 0.207                                                         \n",
      "Average KStest Stat: 0.203                                                         \n",
      "Average KStest Stat: 0.200                                                         \n",
      "Average KStest Stat: 0.212                                                         \n",
      "Average KStest Stat: 0.197                                                         \n",
      "Average KStest Stat: 0.204                                                         \n",
      "Average KStest Stat: 0.209                                                         \n",
      "Average KStest Stat: 0.204                                                         \n",
      "Average KStest Stat: 0.199                                                         \n",
      "Average KStest Stat: 0.203                                                         \n",
      "Average KStest Stat: 0.206                                                         \n",
      "Average KStest Stat: 0.204                                                         \n",
      "Average KStest Stat: 0.212                                                         \n",
      "Average KStest Stat: 0.209                                                         \n",
      "Average KStest Stat: 0.207                                                         \n",
      "Average KStest Stat: 0.203                                                         \n",
      "Average KStest Stat: 0.196                                                         \n",
      "Average KStest Stat: 0.217                                                         \n",
      "Average KStest Stat: 0.208                                                         \n",
      "Average KStest Stat: 0.206                                                         \n",
      "Average KStest Stat: 0.210                                                         \n",
      "Average KStest Stat: 0.213                                                         \n",
      "Average KStest Stat: 0.262                                                         \n",
      "Average KStest Stat: 0.228                                                         \n",
      "Average KStest Stat: 0.197                                                         \n",
      "Average KStest Stat: 0.239                                                         \n",
      "Average KStest Stat: 0.286                                                         \n",
      "Average KStest Stat: 0.217                                                         \n",
      "Average KStest Stat: 0.209                                                         \n",
      "Average KStest Stat: 0.205                                                         \n",
      "Average KStest Stat: 0.207                                                         \n",
      "Average KStest Stat: 0.212                                                         \n",
      "100%|██████████| 100/100 [02:49<00:00,  1.69s/trial, best loss: 0.19620253164556958]\n",
      "The best hyperparameters are :  \n",
      "\n",
      "{'learning_rate': 0.19966693827808601, 'max_depth': 16, 'n_estimators': 96}\n"
     ]
    }
   ],
   "source": [
    "# Optimizing hyperparameters using hyperopt???\n",
    "# Bayesian Optimization\n",
    "if __name__ == \"__main__\":\n",
    "    space = {'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
    "             'max_depth': hp.quniform('max_depth', 2, 18, 1),\n",
    "             #'subsample' : hp.uniform('subsample', 0.5, 1),\n",
    "             #'min_child_weight' : hp.quniform('min_child_weight', 0, 5, 1),\n",
    "             #'max_delta_step' : hp.quniform('max_delta_step', 0, 10, 1),\n",
    "             #'min_split_loss': hp.uniform ('min_split_loss', 1,9),\n",
    "             #'reg_alpha' : hp.quniform('reg_alpha', 40, 180,1),\n",
    "             #'reg_lambda' : hp.uniform('reg_lambda', 0, 1),\n",
    "             #'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
    "             #'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "             'n_estimators' : hp.uniformint('n_estimators', 5, 100),\n",
    "             'seed': 0\n",
    "            }\n",
    "    \n",
    "    trials = Trials()\n",
    "\n",
    "    data = new_in_df.drop(columns = \"label\")\n",
    "    label = new_in_df[\"label\"]\n",
    "\n",
    "    best_hyperparams = fmin(fn = objective,\n",
    "                            space = space,\n",
    "                            algo = tpe.suggest,\n",
    "                            max_evals = 100,\n",
    "                            trials = trials\n",
    "                           )\n",
    "    \n",
    "    best_hyperparams_int = {k:(int(v) if int(float(v)) == v else v) for k,v in best_hyperparams.items()}       \n",
    "    print(\"The best hyperparameters are : \",\"\\n\")\n",
    "    print(best_hyperparams_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fdebef-de04-4e46-a402-5f22a90e4a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://davetang.org/muse/2012/04/17/comparing-different-distributions/\n",
    "# https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test#Two-sample_Kolmogorov.E2.80.93Smirnov_test\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kstest.html\n",
    "# or https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ks_2samp.html\n",
    "# ?\n",
    "# Also https://en.wikipedia.org/wiki/Anderson%E2%80%93Darling_test\n",
    "# https://asaip.psu.edu/articles/beware-the-kolmogorov-smirnov-test/\n",
    "# OK Darling compares against a known distribution so that won't work ha(!)\n",
    "# The null hypothesis is that both samples come from the same distribution and is not rejected (p-value = 0.5361) since they do come from the exact same distribution.\n",
    "\n",
    "# We can try making this the metric but according to this answer on stackexchange https://stats.stackexchange.com/a/511714\n",
    "# we might be better served leaving it as MSE (especially if it's not differentiable) and use that for evaluation only\n",
    "#scipy.stats.kstest(rvs, cdf, args=(), N=20, alternative='two-sided', method='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "80a160a2-6a0a-4c4d-b77a-350b62d4e183",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Eval\n",
      "magnitude_sersic_1: 1.5563\n",
      "sersic_index_sersic_1: 1.9373\n",
      "axis_ratio_sersic_1: 0.2646\n",
      "position_angle_sersic_1: 55.4300\n",
      "magnitude_sersic_2: 0.8461\n",
      "effective_radius_sersic_2: 7.0303\n",
      "sersic_index_sersic_2: 0.6772\n",
      "axis_ratio_sersic_2: 0.1891\n",
      "position_angle_sersic_2: 58.7081\n",
      "cumul_rot_power_2: 206.5808\n",
      "powerlaw_power_2: 9.3026\n",
      "sky_position_angle_power_2: 56.8908\n",
      "\n",
      "KSTest eval\n",
      "magnitude_sersic_1\n",
      "KstestResult(statistic=0.10126582278481013, pvalue=0.816050726346802, statistic_location=13.8839, statistic_sign=1)\n",
      "Insignificant: Test and prediction distributions do not differ signficantly.\n",
      "\n",
      "sersic_index_sersic_1\n",
      "KstestResult(statistic=0.17721518987341772, pvalue=0.16769086609413486, statistic_location=0.68595344, statistic_sign=-1)\n",
      "Insignificant: Test and prediction distributions do not differ signficantly.\n",
      "\n",
      "axis_ratio_sersic_1\n",
      "KstestResult(statistic=0.27848101265822783, pvalue=0.004190220170180564, statistic_location=0.7048072, statistic_sign=-1)\n",
      "Significant: Test and prediction distributions differ significantly.\n",
      "\n",
      "position_angle_sersic_1\n",
      "KstestResult(statistic=0.22784810126582278, pvalue=0.032783641954619344, statistic_location=0.80108863, statistic_sign=1)\n",
      "Significant: Test and prediction distributions differ significantly.\n",
      "\n",
      "magnitude_sersic_2\n",
      "KstestResult(statistic=0.12658227848101267, pvalue=0.5542881699689268, statistic_location=13.689334, statistic_sign=-1)\n",
      "Insignificant: Test and prediction distributions do not differ signficantly.\n",
      "\n",
      "effective_radius_sersic_2\n",
      "KstestResult(statistic=0.11392405063291139, pvalue=0.6878282087774076, statistic_location=21.4364, statistic_sign=1)\n",
      "Insignificant: Test and prediction distributions do not differ signficantly.\n",
      "\n",
      "sersic_index_sersic_2\n",
      "KstestResult(statistic=0.31645569620253167, pvalue=0.000673273747704539, statistic_location=0.5738, statistic_sign=1)\n",
      "Significant: Test and prediction distributions differ significantly.\n",
      "\n",
      "axis_ratio_sersic_2\n",
      "KstestResult(statistic=0.22784810126582278, pvalue=0.032783641954619344, statistic_location=0.7459345, statistic_sign=-1)\n",
      "Significant: Test and prediction distributions differ significantly.\n",
      "\n",
      "position_angle_sersic_2\n",
      "KstestResult(statistic=0.22784810126582278, pvalue=0.032783641954619344, statistic_location=2.340417, statistic_sign=-1)\n",
      "Significant: Test and prediction distributions differ significantly.\n",
      "\n",
      "cumul_rot_power_2\n",
      "KstestResult(statistic=0.17721518987341772, pvalue=0.16769086609413486, statistic_location=0.26674035, statistic_sign=1)\n",
      "Insignificant: Test and prediction distributions do not differ signficantly.\n",
      "\n",
      "powerlaw_power_2\n",
      "KstestResult(statistic=0.13924050632911392, pvalue=0.43023321410525717, statistic_location=-0.63962704, statistic_sign=-1)\n",
      "Insignificant: Test and prediction distributions do not differ signficantly.\n",
      "\n",
      "sky_position_angle_power_2\n",
      "KstestResult(statistic=0.17721518987341772, pvalue=0.16769086609413486, statistic_location=2.4380987, statistic_sign=-1)\n",
      "Insignificant: Test and prediction distributions do not differ signficantly.\n",
      "\n",
      "7/12 prediction distributions match within p < 0.05\n"
     ]
    }
   ],
   "source": [
    "# Regresssion\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # If chosen by hand\n",
    "    param = {\"tree_method\"   : \"hist\",\n",
    "             \"n_estimators\"  : 120, \n",
    "             \"max_depth\"     : 6, \n",
    "             \"learning_rate\" : 0.15}\n",
    "             #\"objective\"     : \"binary:logistic\"}\n",
    "\n",
    "    reg = xgb.XGBRegressor(#**param\n",
    "                           **best_hyperparams_int\n",
    "                           )\n",
    "                           \n",
    "    reg.fit(in_train, \n",
    "            out_train, \n",
    "            eval_set = [(in_train, out_train)],\n",
    "            verbose = False)\n",
    "\n",
    "    reg_pred = reg.predict(in_test)\n",
    "    out_pred_df = pd.DataFrame(reg_pred, \n",
    "                               columns = out_test.columns, \n",
    "                               index = in_test.index\n",
    "                              )\n",
    "\n",
    "    # squared = False gives RMSE\n",
    "    rmse = MSE(out_test, \n",
    "               reg_pred, \n",
    "               multioutput = \"raw_values\", \n",
    "               squared = False\n",
    "              )\n",
    "\n",
    "    print(\"RMSE Eval\")\n",
    "    for col, score in zip(out_train.columns, rmse):\n",
    "        if \"cumul_rot\" in col or \"position_angle\" in col.lower():\n",
    "            score *= 180/np.pi\n",
    "        print(f\"{col}: {score:.4f}\")\n",
    "\n",
    "    print()\n",
    "    print(\"KSTest eval\")\n",
    "    # Null hypothesis -- the samples are pulled from the same distribution\n",
    "    # typical choice is <0.05, reject null hypothesis\n",
    "    kstest_results = {col : kstest(out_test[col].values, out_pred_df[col].values)\n",
    "                      for col in out_pred_df}\n",
    "\n",
    "    insig_count = 0\n",
    "    for col, result in kstest_results.items():\n",
    "        print(col)\n",
    "        print(result)\n",
    "        if result.pvalue < 0.05:\n",
    "            result_str = \"Significant: Test and prediction distributions differ significantly.\"\n",
    "        else:\n",
    "            result_str = \"Insignificant: Test and prediction distributions do not differ signficantly.\"\n",
    "            insig_count += 1\n",
    "        print(result_str)\n",
    "        print()\n",
    "    print(f\"{insig_count}/{len(kstest_results)} prediction distributions match within p < 0.05\")\n",
    "\n",
    "    #plot_predt(out_train.to_numpy(), reg_pred, \"multi\")\n",
    "    # Closer to 1 is better \n",
    "    # https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.XGBRegressor.score\n",
    "    # I'm thinking R^2 isn't a good test here, just looking at the data\n",
    "    # reg.score(in_test, out_test)\n",
    "\n",
    "    # TODO: Can we average the difference of every parameter per galaxy and use that to evaluate the model on a per galaxy basis?\n",
    "    # With some weighting I think"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af38fbfd-878d-48a1-ac4f-57ca797cf888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def anderson_darling(in_df):\n",
    "#     # Null hypothesis -- the samples are pulled from the normal distribution\n",
    "#     # statistic is the 'result', critical_values are the values at which we can check each\n",
    "#     # significance level specified by significance_level\n",
    "#     # The statistic must be greater than a critical value to determine a significance value\n",
    "#     #\n",
    "#     # ex: statistic = 0.8\n",
    "#     # significance array (%) = [15. , 10. ,  5. ,  2.5,  1. ]\n",
    "#     # critical values        = [0.552, 0.629, 0.755, 0.88 , 1.047]\n",
    "#     # Then the result is significant at the 5%/0.05 confidence level\n",
    "    \n",
    "#     anderson_results = {col : anderson(in_df[col].values, dist = 'norm')\n",
    "#                         for col in in_df}\n",
    "    \n",
    "#     crit_sig = dict(zip(list(anderson_results.values())[0].critical_values, \n",
    "#                         list(anderson_results.values())[0].significance_level))\n",
    "    \n",
    "#     cv = list(crit_sig.keys())\n",
    "#     sl = list(crit_sig.values())\n",
    "    \n",
    "#     print(f\"Critical Values: {cv}\")\n",
    "#     print(f\"Significance Levels: {sl}\")\n",
    "#     print()\n",
    "    \n",
    "#     for col, result in anderson_results.items():\n",
    "#         rs = result.statistic\n",
    "#         # Checking highest crit val the significance is greater than\n",
    "#         cv_filter = list(filter(lambda x: rs > x, cv))\n",
    "#         if cv_filter:\n",
    "#             significance_value = crit_sig[cv_filter[-1]]\n",
    "#         else:\n",
    "#             significance_value = \"N/A\"\n",
    "            \n",
    "#         print(f\"{col}\\n{rs}, satisfies {significance_value} confidence level\\n\", sep = \"\")\n",
    "    \n",
    "#     return anderson_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "50c0f52f-e301-4528-b5a8-a51cd3341087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Anderson-Darling eval of prediction (vs Normal Distribution)\n",
      "Critical Values: [0.55, 0.627, 0.752, 0.877, 1.043]\n",
      "Significance Levels: [15.0, 10.0, 5.0, 2.5, 1.0]\n",
      "\n",
      "magnitude_sersic_1\n",
      "0.3379822872302043, satisfies N/A confidence level\n",
      "\n",
      "sersic_index_sersic_1\n",
      "13.381663129794262, satisfies 1.0 confidence level\n",
      "\n",
      "axis_ratio_sersic_1\n",
      "1.9512935148939619, satisfies 1.0 confidence level\n",
      "\n",
      "position_angle_sersic_1\n",
      "0.6886941780897473, satisfies 10.0 confidence level\n",
      "\n",
      "magnitude_sersic_2\n",
      "1.0955898035035432, satisfies 1.0 confidence level\n",
      "\n",
      "effective_radius_sersic_2\n",
      "1.9438571326921164, satisfies 1.0 confidence level\n",
      "\n",
      "sersic_index_sersic_2\n",
      "1.4037887654092032, satisfies 1.0 confidence level\n",
      "\n",
      "axis_ratio_sersic_2\n",
      "0.547236267077551, satisfies N/A confidence level\n",
      "\n",
      "position_angle_sersic_2\n",
      "0.19540819520564412, satisfies N/A confidence level\n",
      "\n",
      "cumul_rot_power_2\n",
      "0.16842935699413886, satisfies N/A confidence level\n",
      "\n",
      "powerlaw_power_2\n",
      "1.9227335040144027, satisfies 1.0 confidence level\n",
      "\n",
      "sky_position_angle_power_2\n",
      "1.5373365433071484, satisfies 1.0 confidence level\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ************************************************************************\n",
    "# Should we expect these subsets to be normal?\n",
    "# ************************************************************************\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\nAnderson-Darling eval of prediction (vs Normal Distribution)\")\n",
    "    _ = anderson_darling(out_pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a15ffaa4-495b-4dcf-9866-0ed50bdb96d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Anderson-Darling eval of test output (vs Normal Distribution)\n",
      "Critical Values: [0.55, 0.627, 0.752, 0.877, 1.043]\n",
      "Significance Levels: [15.0, 10.0, 5.0, 2.5, 1.0]\n",
      "\n",
      "magnitude_sersic_1\n",
      "0.8684949142020599, satisfies 5.0 confidence level\n",
      "\n",
      "sersic_index_sersic_1\n",
      "16.053461118345282, satisfies 1.0 confidence level\n",
      "\n",
      "axis_ratio_sersic_1\n",
      "1.8040859071427064, satisfies 1.0 confidence level\n",
      "\n",
      "position_angle_sersic_1\n",
      "0.856704009057637, satisfies 5.0 confidence level\n",
      "\n",
      "magnitude_sersic_2\n",
      "2.1036483954409135, satisfies 1.0 confidence level\n",
      "\n",
      "effective_radius_sersic_2\n",
      "1.6017656710096304, satisfies 1.0 confidence level\n",
      "\n",
      "sersic_index_sersic_2\n",
      "3.069565618094785, satisfies 1.0 confidence level\n",
      "\n",
      "axis_ratio_sersic_2\n",
      "1.9636298127546468, satisfies 1.0 confidence level\n",
      "\n",
      "position_angle_sersic_2\n",
      "1.3448192063788156, satisfies 1.0 confidence level\n",
      "\n",
      "cumul_rot_power_2\n",
      "4.198073905408961, satisfies 1.0 confidence level\n",
      "\n",
      "powerlaw_power_2\n",
      "19.279376907144766, satisfies 1.0 confidence level\n",
      "\n",
      "sky_position_angle_power_2\n",
      "1.1671753582390352, satisfies 1.0 confidence level\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ************************************************************************\n",
    "# Could be used for interesting statistics once I'm actually confident in the algorithm ;)\n",
    "# ************************************************************************\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\nAnderson-Darling eval of test output (vs Normal Distribution)\")\n",
    "    _ = anderson_darling(out_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea47991f-524c-43fb-9efb-77cf1f0fede9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_hist_plots(test_data, predicted_data, grid = False, bins = 30, adjust = 2.17, save = False):\n",
    "#     # Assume both test_data, predicted_data are pandas df\n",
    "#     # Number of bins arrived at empirically\n",
    "\n",
    "#     rows = len(test_data.columns)\n",
    "#     cols = 1\n",
    "    \n",
    "#     if grid:\n",
    "#         rows = ceil(rows / 2)\n",
    "#         # Restricting to 2 for now since histograms are wide\n",
    "#         cols = 2\n",
    "        \n",
    "#     fig = make_subplots(rows = rows, cols = cols, start_cell=\"top-left\") \n",
    "\n",
    "#     for i, col_name in enumerate(predicted_data.columns): \n",
    "\n",
    "#         # plotly indexes at 1 \n",
    "#         if grid:\n",
    "#             row = ceil((i + 1)/rows) \n",
    "#             col = i % cols + 1 \n",
    "#         else:\n",
    "#             row = i + 1\n",
    "#             col = 1    \n",
    "\n",
    "#         #print(row, col) \n",
    "\n",
    "#         fig.add_trace(go.Histogram(x = test_data[col_name],\n",
    "#                                    nbinsx = bins,\n",
    "#                                    name = \"Data\",\n",
    "#                                    legendgroup = col_name,\n",
    "#                                    legendgrouptitle_text = col_name,\n",
    "#                                    marker_color = '#FFA15A'), #col_name + \" test\"), \n",
    "#                       row = row, col = col) \n",
    "        \n",
    "#         fig.add_trace(go.Histogram(x = predicted_data[col_name],\n",
    "#                                    nbinsx = bins,\n",
    "#                                    name = \"Predicted\",\n",
    "#                                    legendgroup = col_name,\n",
    "#                                    legendgrouptitle_text = col_name,\n",
    "#                                    marker_color = 'cornflowerblue'), #col_name + \" pred\"), \n",
    "#                       row = row, col = col)\n",
    "\n",
    "#         fig.update_layout(barmode='overlay')#,\n",
    "#                           #xaxis_title_text = col_name)\n",
    "            \n",
    "#         # if save:\n",
    "#         #     filepath = pj(cwd, col_name.replace(\" \", \"_\"))\n",
    "#         #     fig.write_image(f\"{filepath}.svg\")\n",
    "\n",
    "#     fig.update_traces(opacity = 0.6)\n",
    "#     height = rows*200\n",
    "#     width = 800\n",
    "#     # For legend placement\n",
    "#     # higher, less distance, lower, more distance\n",
    "#     adjust = adjust\n",
    "#     fig.update_layout(height = height, width = width,\n",
    "#                       legend_tracegroupgap = height / (adjust*len(in_test.columns)))\n",
    "    \n",
    "#     if save:\n",
    "#         filepath = pj(os.getcwd, \"hist_plots\", \"all_plots\")\n",
    "#         fig.write_image(f\"{filepath}.svg\")\n",
    "#     else:\n",
    "#         fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "64d77aae-3fb7-44ad-90b2-64728f96c547",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    make_hist_plots(out_test, out_pred_df, adjust=1.83, save = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6ef9579-cb19-4ec2-b498-6fbdfb541b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    reg.save_model(pj(cwd, \"xgboost_model.json\"))\n",
    "    # reg.load_model(\"xgboost_model.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efdab6f5-9dde-439b-b0fd-7d5a43851612",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting xgboost_train.ipynb\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    export_to_py(\"xgboost_train\", pj(_MODULE_DIR, \"XGBoost\", \"xgboost_train\"))\n",
    "    #export_to_py(\"xgboost_train\", \"xgboost_train\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
